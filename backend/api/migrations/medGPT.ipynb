{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYO37frluNl4"
      },
      "outputs": [],
      "source": [
        "# Vectorize medical document \n",
        "# Semantic search on document\n",
        "# Use it as reference\n",
        "# Give it top 5, get generations, calculate difficulty on them\n",
        "# Have a threshold for ease of understanding\n",
        "# Use medical db as a reference\n",
        "# Once it reaches threshold or top number, give a summarization and provide sources. Try to make this look nice-> show the steps with framer motion\n",
        "# We then need to validate, we need to make sure that gpt was correct, we ask it to extract potentially difficult words into definitions\n",
        "# We need to formulate a question using those definitions to see if chatgpt matches the text\n",
        "# “Is the following text derived from the following information, if not, explain why”\n",
        "# We can then ask chatgpt recursively to resummarize our text until it determines this is relevant\n",
        "# Why not just use the original database for validation, or originally provide the definitions?\n",
        "# At the least, having the definitions at the end is ground truth\n",
        "# But we should probably have the original text to ask it if it matches\n",
        "# The other is too convoluted\n",
        "\n",
        "\n",
        "# Maybe we can just generate tools, and 5 sentence snippets from top documents\n",
        "# We ask it for an x level summarization\n",
        "# We predict what level it is\n",
        "# We do this x times/ or till it reaches the level\n",
        "# When its done, we do validation, using chatgpt, we feed it only the text and ask if this summarization is 100% factual and summarizes the following text\n",
        "# We ask it yes or no, if it says we no, we re run the sequence 3 times (arbtirary)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "['a'] + ['b']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyHVm-dl1YO2",
        "outputId": "f7a4e4c6-61cd-4a15-d2d9-1e9fc455e39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyzJhlehAnF4",
        "outputId": "70431061-9214-40c6-9324-da52023b7af5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.24.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=442cc2e015cb77ceee111226f986dc7c06f2d8f8adc246279dd8e4ef89087a4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.13.1 sentence_transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_docu(file):\n",
        "    acc = \"\"\n",
        "    total = []\n",
        "    with open(file, \"r\", encoding = \"utf-8\") as input_file:\n",
        "        for line in input_file:\n",
        "          if \"###\" in line:\n",
        "            total.append(acc)\n",
        "\n",
        "            acc = \"\"\n",
        "          else:\n",
        "            acc += line\n",
        "          \n",
        "         \n",
        "\n",
        "            # line = line.lower()\n",
        "            # line = line.strip().split()\n",
        "            # all_words += line\n",
        "        return(total)"
      ],
      "metadata": {
        "id": "W7CmF-AbALrr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpa = read_docu(\"/content/train.txt\")"
      ],
      "metadata": {
        "id": "W9pHXGwMFGIU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUhgw6sFJdN",
        "outputId": "2ab2a11b-1d36-4fc5-a28e-270d61608469"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190656"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "kDJWZPj6HPMz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2R8ZtuSIHXi",
        "outputId": "0e8f9d35-c660-4d22-afee-78afa5a317bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_vis(list_of_strings):\n",
        "    # Combine the list of strings into one text data\n",
        "    text = \" \".join(list_of_strings)\n",
        "    \n",
        "    # Tokenize the text data\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Generate word frequency distribution\n",
        "    word_freq = nltk.FreqDist(tokens)\n",
        "\n",
        "    # Generate text length and word length lists\n",
        "    text_length = len(text)\n",
        "    word_lengths = [len(word) for word in tokens]\n",
        "\n",
        "    # Visualize the statistics using matplotlib\n",
        "    word_freq.plot(30, cumulative=False)\n",
        "    plt.title('Word Frequency Distribution')\n",
        "    plt.xlabel('Word')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    plt.hist(text_length, bins=50)\n",
        "    plt.title('Text Length Histogram')\n",
        "    plt.xlabel('Text Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    plt.hist(word_lengths, bins=20)\n",
        "    plt.title('Word Length Histogram')\n",
        "    plt.xlabel('Word Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PDfZfDeOIDl4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_vis(corpa[:1000])"
      ],
      "metadata": {
        "id": "r8M8uZ9UIDqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4Fu6PDar6S",
        "outputId": "e613e3f2-03f5-4404-88ea-d96b96e33db4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190656"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vecs = vectorize_document(corpa[:10])"
      ],
      "metadata": {
        "id": "AKemJIGLaSql"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9rIfp0T4sMr",
        "outputId": "c6e1f650-e295-4e42-f6c3-f0e98fd8c659"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02487659,  0.03533099, -0.03575214, ..., -0.05154072,\n",
              "         0.08841205,  0.01115166],\n",
              "       [-0.0409755 ,  0.12061245, -0.04079222, ..., -0.02661899,\n",
              "        -0.00992622,  0.02157138],\n",
              "       [-0.01809083,  0.03765663,  0.02531192, ..., -0.02202033,\n",
              "         0.02595152,  0.04294702],\n",
              "       ...,\n",
              "       [ 0.0577273 ,  0.04588984, -0.00436507, ..., -0.109672  ,\n",
              "        -0.01745167,  0.08131375],\n",
              "       [ 0.10112737, -0.03177056,  0.04541111, ...,  0.0469774 ,\n",
              "        -0.07129978, -0.04439046],\n",
              "       [-0.04486382,  0.03724546, -0.06000146, ..., -0.02757619,\n",
              "         0.02477676, -0.01657726]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQpQTBMx396G",
        "outputId": "85687001-64cf-4997-c75b-ef722aa95ab0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNw9NLa7AMYW",
        "outputId": "ebc1b4d7-9f54-4b7b-9192-8934902ead76"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, charset-normalizer, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=\"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\"\n",
        "OPEN_AI_ORG_KEY=\"org-w3pzkJvfH1OVGYWqigk0JqjE\""
      ],
      "metadata": {
        "id": "F82I9_MABRAg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.organization = OPEN_AI_ORG_KEY\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "openai.Model.list()"
      ],
      "metadata": {
        "id": "A3K7eKHdBLal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTX2ddPvEf0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            \"content\":\"hello chatgpt!\",\n",
        "         \"role\": \"assistant\"\n",
        "        }\n",
        "    ]\n",
        " \n",
        "    \n",
        ")\n",
        "\n",
        "\n",
        "res = response\n"
      ],
      "metadata": {
        "id": "x5WzqOvjCvYa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['choices'][0]['message'][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5avm4XpDEIg6",
        "outputId": "6ec4ceb8-bae1-41ad-8b79-7ad7de3e4570"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nHello! How may I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RFd2C6FEbqm",
        "outputId": "fdbb7e22-736f-4d7b-a9ef-dc519b855949"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-6sypFMCnaoBeZinvJnNbDVFaPq3iI at 0x7f3a106a8220> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"\\n\\nHello! How may I assist you today?\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1678561545,\n",
              "  \"id\": \"chatcmpl-6sypFMCnaoBeZinvJnNbDVFaPq3iI\",\n",
              "  \"model\": \"gpt-3.5-turbo-0301\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 11,\n",
              "    \"prompt_tokens\": 12,\n",
              "    \"total_tokens\": 23\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-tnpp0eEHKxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "\n",
        "query_embedding = model.encode('How big is London')\n",
        "passage_embedding = model.encode(['London has 9,787,426 inhabitants at the 2011 census',\n",
        "                                  'London is known for its finacial district','London is known for its finacial district','London is known for its finacial district','London is known for its finacial district','London is known for its finacial district''London is known for its finacial district','London is known for its finacial district'])\n",
        "\n",
        "print(\"Similarity:\", util.dot_score(query_embedding, passage_embedding))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw6IkBt0Amma",
        "outputId": "d8099342-eb86-4df8-f149-6778e45a1b1a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: tensor([[0.5472, 0.6330, 0.6330, 0.6330, 0.6330, 0.4866, 0.6330]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_indices(lst, n):\n",
        "    # Use enumerate() to get the indices of each element in the list\n",
        "    # Then use sorted() with a key function that sorts by the value of each element\n",
        "    # Finally, use a list comprehension to get the first 5 indices in the sorted list\n",
        "    return [i for i, _ in sorted(enumerate(lst), key=lambda x: x[1], reverse=True)[:n]]"
      ],
      "metadata": {
        "id": "QyoVwbkQDeHn"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fffff = util.dot_score(query_embedding, passage_embedding)"
      ],
      "metadata": {
        "id": "v6quVfCuDCqp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fffff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reqFgwopDVSU",
        "outputId": "afc8bf02-e446-4c47-854e-6553e8475412"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5472, 0.6330, 0.6330, 0.6330, 0.6330, 0.4866, 0.6330]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_sim = [i.item() for i in list(fffff[0])]"
      ],
      "metadata": {
        "id": "nXejAH24DHxv"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_5_indices(scores_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UCVz8ESDgeM",
        "outputId": "491e9e55-2013-4ace-cb1f-b480d5812edc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(passage_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh-3JJ2JEypO",
        "outputId": "8b59bfaf-faf7-4e27-dfb6-9d81b8204114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passage_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6EVNICmE3-3",
        "outputId": "dc507898-94c5-4325-f404-8c09c956c7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.12549895, -0.01423618,  0.06823373, ...,  0.04764374,\n",
              "        -0.07658362,  0.01015001],\n",
              "       [ 0.20452398, -0.01486543,  0.03295963, ...,  0.0188743 ,\n",
              "        -0.07937784,  0.04315905],\n",
              "       [ 0.20452398, -0.01486543,  0.03295963, ...,  0.0188743 ,\n",
              "        -0.07937784,  0.04315905],\n",
              "       [ 0.20452398, -0.01486543,  0.03295963, ...,  0.0188743 ,\n",
              "        -0.07937784,  0.04315905]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "util.cos_sim(query_embedding,passage_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlkEp9T7Eghq",
        "outputId": "4f33edb4-0615-42fc-f15c-6404d0395423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5472, 0.6330, 0.6330, 0.6330]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, BertForSequenceClassification, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "rDyf0x5aERwa"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complexity_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "\n",
        "\n",
        "# loading model\n",
        "# PATH = \"./pytorchBERTmodel\"\n",
        "# PATH = \"../ml_models/pytorchBERTmodel\"\n",
        "bert_model = torch.load(\"pytorchBERTmodel\", map_location=torch.device(\"cpu\"))\n",
        "bert_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBpzfW_GEV1o",
        "outputId": "ff69c85f-e248-43b5-d1df-080263f180a5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGqW3yEOEsOL",
        "outputId": "791fe11a-b6f6-4a3b-e239-a53ba2d333ac"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4035]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, tokenizer=complexity_tokenizer):\n",
        "    bert_model.eval()\n",
        "    bert_model.to('cpu')\n",
        "\n",
        "    def prepare_data(text, tokenizer=complexity_tokenizer):\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=315,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded_text['input_ids'])\n",
        "        attention_masks.append(encoded_text['attention_mask'])\n",
        "\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n",
        "\n",
        "    tokenized_example_text = prepare_data(text, complexity_tokenizer)\n",
        "    with torch.no_grad():\n",
        "        result = bert_model(\n",
        "            tokenized_example_text['input_ids'].to('cpu'),\n",
        "            attention_mask=tokenized_example_text['attention_masks'].to('cpu'),\n",
        "            return_dict=True\n",
        "        ).logits\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "caYpAAZ9EOKl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_chatgpt(\"\"\"whats the square root of pi\"\"\")"
      ],
      "metadata": {
        "id": "0K9qQ715EO2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e2e606e-96f7-4cce-d02e-6d075e7a9890"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe square root of pi is approximately 1.77245385091.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_search_terms('$Merriam-Webster(\"Simplify\")SUPPLEMENTAL INFORMATION: In medical te')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M52wvItiCMqk",
        "outputId": "ed7da25c-85cf-4089-c2f2-8f5d4ccc35c5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'tool_name': 'Webster', 'search_term': '\"Simplify\"'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idka = generate_search_terms('$Merriam-Webster(\"disease\") fdsafasdfadsf ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir2i41iiDA0B",
        "outputId": "be08a5f5-2182-41d5-94a3-ad3f142e1ded"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the words gpt wants $Merriam-Webster(\"disease\") fdsafasdfadsf \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = generate_definitions(idka)\n",
        "type(res)\n",
        "res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L5-5YEoJrMl",
        "outputId": "7bb3ebaf-0b05-4a07-92c6-481ec92683bf"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "desiredwords [{'tool_name': 'Webster', 'search_term': '\"disease\"'}]\n",
            "b'[{\"meta\":{\"id\":\"disease\",\"uuid\":\"4b1c483c-a661-41e9-bc4e-d4b7b1c255e0\",\"sort\":\"041324000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"disease\",\"diseased\",\"diseases\",\"morbus\"],\"offensive\":false},\"hwi\":{\"hw\":\"dis*ease\",\"prs\":[{\"mw\":\"diz-\\\\u02c8\\\\u0113z\",\"sound\":{\"audio\":\"diseas01\"}}]},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}an impairment of the normal state of the living animal or plant body or one of its parts that interrupts or modifies the performance of the vital functions, is typically manifested by distinguishing signs and symptoms, and is a response to environmental factors (as malnutrition, industrial hazards, or climate), to specific infective agents (as worms, bacteria, or viruses), to inherent defects of the organism (as genetic anomalies), or to combinations of these factors {bc}{sx|sickness|sickness|}, {sx|illness|illness|} \"],[\"ca\",{\"intro\":\"called also\",\"cats\":[{\"cat\":\"morbus\"}]}],[\"text\",\" {dx}compare {dxt|health|health|1}{\\\\/dx}\"]]}]]]}],\"uros\":[{\"ure\":\"dis*eased\",\"prs\":[{\"mw\":\"-\\\\u02c8\\\\u0113zd\",\"sound\":{\"audio\":\"diseas02\"}}],\"fl\":\"adjective\"}],\"shortdef\":[\"an impairment of the normal state of the living animal or plant body or one of its parts that interrupts or modifies the performance of the vital functions, is typically manifested by distinguishing signs and symptoms, and is a response to environmental factors (as malnutrition, industrial hazards, or climate), to specific infective agents (as worms, bacteria, or viruses), to inherent defects of the organism (as genetic anomalies), or to combinations of these factors : sickness, illness \\\\u2014called also morbus\"]},{\"meta\":{\"id\":\"acrodynia\",\"uuid\":\"dbe56536-36c7-4885-ae5a-9bf9d665a6bc\",\"sort\":\"010480000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Swift\\\\u0027s disease\",\"acrodynia\",\"acrodynias\",\"acrodynic\",\"erythredema\",\"pink disease\"],\"offensive\":false},\"hwi\":{\"hw\":\"ac*ro*dyn*ia\",\"prs\":[{\"mw\":\"\\\\u02ccak-r\\\\u014d-\\\\u02c8din-\\\\u0113-\\\\u0259\",\"sound\":{\"audio\":\"acrod04m\"}}]},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}a disease of infants and young children that is an allergic reaction to mercury, is characterized by dusky pink discoloration of hands and feet with local swelling and intense itching, and is accompanied by insomnia, irritability, and sensitivity to light \"],[\"ca\",{\"intro\":\"called also\",\"cats\":[{\"cat\":\"erythredema\"},{\"cat\":\"pink disease\"},{\"cat\":\"Swift\\\\u0027s disease\"}]}]]}]]]}],\"uros\":[{\"ure\":\"ac*ro*dyn*ic\",\"prs\":[{\"mw\":\"-\\\\u02c8din-ik\",\"sound\":{\"audio\":\"acrod05m\"}}],\"fl\":\"adjective\"}],\"shortdef\":[\"a disease of infants and young children that is an allergic reaction to mercury, is characterized by dusky pink discoloration of hands and feet with local swelling and intense itching, and is accompanied by insomnia, irritability, and sensitivity to light \\\\u2014called also erythredema, pink disease, Swift\\\\u0027s disease\"]},{\"meta\":{\"id\":\"Adams-Stokes disease\",\"uuid\":\"171d033f-4248-4e5d-93a1-de670bcac82a\",\"sort\":\"010626000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Adams-Stokes disease\"],\"offensive\":false},\"hwi\":{\"hw\":\"Adams-Stokes disease\"},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}{sx|stokes-adams syndrome|stokes-adams syndrome|}\"]]}]]]}],\"shortdef\":[\"stokes-adams syndrome\"]},{\"meta\":{\"id\":\"Addison\\\\u0027s disease\",\"uuid\":\"0dc17712-4dfe-4fd8-81a1-247b12b1d7ec\",\"sort\":\"010653000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Addison\\\\u0027s disease\"],\"offensive\":false},\"hwi\":{\"hw\":\"Addison\\\\u0027s disease\"},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}a rare disease marked by deficient secretion of {d_link|adrenocortical|adrenocortical} hormones (such as cortisol) that is characterized by fatigue, muscle weakness, weight loss, low blood pressure, irritability or depression, and brownish pigmentation of the skin and is caused by progressive destruction of the {d_link|adrenal glands|adrenal gland} (as by an autoimmune response or infection)\"]]}]]]}],\"shortdef\":[\"a rare disease marked by deficient secretion of adrenocortical hormones (such as cortisol) that is characterized by fatigue, muscle weakness, weight loss, low blood pressure, irritability or depression, and brownish pigmentation of the skin and is caused by progressive destruction of the adrenal glands (as by an autoimmune response or infection)\"]},{\"meta\":{\"id\":\"adrenoleukodystrophy\",\"uuid\":\"c19e2e28-b7e7-4c2c-8d72-cd05cb5236c3\",\"sort\":\"010809000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Schilder\\\\u0027s disease\",\"Schilder\\\\u0027s encephalitis\",\"adrenoleucodystrophy\",\"adrenoleukodystrophies\",\"adrenoleukodystrophy\",\"encephalitis periaxialis diffusa\"],\"offensive\":false},\"hwi\":{\"hw\":\"adre*no*leu*ko*dys*tro*phy\"},\"vrs\":[{\"vl\":\"or chiefly British\",\"va\":\"adre*no*leu*co*dys*tro*phy\",\"prs\":[{\"mw\":\"-\\\\u02ccl\\\\u00fc-k\\\\u014d-\\\\u02c8dis-tr\\\\u0259-f\\\\u0113\",\"sound\":{\"audio\":\"adren12m\"}}]}],\"fl\":\"noun\",\"ins\":[{\"il\":\"plural\",\"ifc\":\"-phies\",\"if\":\"adre*no*leu*ko*dys*tro*phies\"}],\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}a rare demyelinating disease of the central nervous system that is inherited as an X-linked recessive trait chiefly affecting males in childhood and that is characterized by progressive blindness, deafness, tonic spasms, and mental deterioration \"],[\"uns\",[[[\"text\",\"abbreviation {it}ALD{\\\\/it}\"]]]],[\"ca\",{\"intro\":\"called also\",\"cats\":[{\"cat\":\"encephalitis periaxialis diffusa\"},{\"cat\":\"Schilder\\\\u0027s disease\"},{\"cat\":\"Schilder\\\\u0027s encephalitis\"}]}]]}]]]}],\"shortdef\":[\"a rare demyelinating disease of the central nervous system that is inherited as an X-linked recessive trait chiefly affecting males in childhood and that is characterized by progressive blindness, deafness, tonic spasms, and mental deterioration \\\\u2014abbreviation ALD\\\\u2014called also encephalitis periaxialis diffusa, Schilder\\\\u0027s disease, Schilder\\\\u0027s encephalitis\"]},{\"meta\":{\"id\":\"Albers-Sch\\\\u0027onberg disease\",\"uuid\":\"33b9a4eb-fb65-448b-94e9-812712e5c463\",\"sort\":\"011097000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Albers-Schonberg\",\"Albers-Schonberg disease\"],\"offensive\":false},\"hwi\":{\"hw\":\"Al*bers-Sch\\\\u00f6n*berg disease\",\"prs\":[{\"mw\":\"\\\\u02c8al-b\\\\u0259rz-\\\\u02c8sh\\\\u0259rn-\\\\u02ccb\\\\u0259rg-\",\"sound\":{\"audio\":\"alber01m\"}},{\"mw\":\"-\\\\u02c8sh\\\\u014dn-\",\"sound\":{\"audio\":\"alber02m\"}}]},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}{sx|osteopetrosis|osteopetrosis|a}\"]]}]]]}],\"bios\":[[[\"bionw\",{\"biosname\":\"Albers\\\\u2013Sch\\\\u00f6nberg\",\"prs\":[{\"mw\":\"\\\\u02c8\\\\u00e4l-\\\\u02ccbers-\\\\u02c8sh\\\\u0153\\\\u0305n-\\\\u02ccberk\"}]}],[\"bionw\",{\"biopname\":\"Heinrich Ernst\"}],[\"biodate\",\"(1865\\\\u20131921)\"],[\"biotx\",\"German roentgenologist. Albers-Sch\\\\u00f6nberg was the first specialist in the field of roentgenology (now called radiology). He held the post of professor of roentgenology and founded an institute of roentgenology in Germany. He is credited with discovering that X-rays can cause damage to the reproductive organs. In 1903 he introduced a device consisting of a moving grid of lead strips used for producing sharper X-ray images by eliminating the oblique rays that pass through them before reaching the film. He described osteopetrosis, now also known as Albers-Sch\\\\u00f6nberg disease, in a paper in a journal published in 1903\\\\u201304.\"]]],\"shortdef\":[\"osteopetrosis\"]},{\"meta\":{\"id\":\"alkali disease\",\"uuid\":\"928fdb4c-85d7-42e9-9e39-9924c559d467\",\"sort\":\"011224000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"alkali disease\",\"alkali diseases\"],\"offensive\":false},\"hwi\":{\"hw\":\"alkali disease\"},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}{sx|selenosis|selenosis|}\"]]}]]]}],\"shortdef\":[\"selenosis\"]},{\"meta\":{\"id\":\"alpha chain disease\",\"uuid\":\"5303c161-b8f5-4202-b41c-bf9ed9425b4b\",\"sort\":\"011363000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"alpha chain disease\"],\"offensive\":false},\"hwi\":{\"hw\":\"alpha chain disease\"},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}{sx|immunoproliferative small intestinal disease|immunoproliferative small intestinal disease|}\"]]}]]]}],\"shortdef\":[\"immunoproliferative small intestinal disease\"]},{\"meta\":{\"id\":\"Alzheimer\\\\u0027s disease\",\"uuid\":\"42104d2c-b8cb-40fb-8454-d9051e27dcec\",\"sort\":\"011460000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Alzheimer\",\"Alzheimer disease\",\"Alzheimer\\\\u0027s\",\"Alzheimer\\\\u0027s disease\",\"Alzheimer\\\\u0027s diseases\"],\"offensive\":false},\"hwi\":{\"hw\":\"Alz*hei*mer\\\\u0027s disease\",\"prs\":[{\"mw\":\"\\\\u02c8\\\\u00e4lts-\\\\u02cch\\\\u012b-m\\\\u0259rz-\",\"sound\":{\"audio\":\"alzhei01\"}},{\"mw\":\"\\\\u02c8\\\\u022flts-\",\"sound\":{\"audio\":\"alzhe01m\"}},{\"mw\":\"\\\\u02c8alts-\",\"sound\":{\"audio\":\"alzhei02\"}},{\"mw\":\"\\\\u02c8alz-\",\"sound\":{\"audio\":\"alzhe02m\"}}]},\"vrs\":[{\"vl\":\"also\",\"va\":\"Alzheimer disease\",\"prs\":[{\"mw\":\"-m\\\\u0259r\",\"sound\":{\"audio\":\"alzhei03\"}}]},{\"vl\":\"or\",\"va\":\"Alzheimer\\\\u0027s\"}],\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}a degenerative brain disease of unknown cause that is the most common form of dementia, that usually starts in late middle age or in old age, that results in progressive memory loss, impaired thinking, disorientation, and changes in personality and mood, that leads in advanced cases to a profound decline in cognitive and physical functioning, and that is marked histologically by the degeneration of brain neurons especially in the cerebral cortex and by the presence of neurofibrillary tangles and plaques containing beta-amyloid \"],[\"vis\",[{\"t\":\"Behavioral problems, such as mood swings and agitation, may also be a part of the progression of {it}Alzheimer\\\\u0027s disease{\\\\/it}.\",\"aq\":{\"auth\":\"Allan Perel\",\"source\":\"{it}The Staten Island (New York) Advance{\\\\/it}\"}},{\"t\":\"{it}Alzheimer disease{\\\\/it} (AD) is the most common cause of dementia, affecting more than 15 million individuals worldwide.\",\"aq\":{\"auth\":\"Niklas Mattsson et al.\",\"source\":\"{it}The Journal of the American Medical Association{\\\\/it}\"}},{\"t\":\"\\\\u2026 researchers in California have created mice carrying the gene for beta-amyloid protein, the principal component of the plaques riddling the brains of people with {it}Alzheimer\\\\u0027s{\\\\/it}.\",\"aq\":{\"auth\":\"Charlene Crabb\",\"source\":\"{it}U.S. News \\\\u0026 World Report{\\\\/it}\"}}]],[\"uns\",[[[\"text\",\"abbreviation {it}AD{\\\\/it}\"]]]]]}]]]}],\"bios\":[[[\"bionw\",{\"biosname\":\"Alzheimer\"}],[\"bionw\",{\"biopname\":\"Alois\"}],[\"biodate\",\"(1864\\\\u20131915)\"],[\"biotx\",\"German neurologist. Alzheimer was noted for his work in the pathology of the nervous system. The majority of his medical contributions centered on neurohistology. Alzheimer published papers on topics that include acute alcoholic delirium, schizophrenia, epilepsy, syphilitic meningomyelitis and encephalitis, gliosis, Huntington\\\\u0027s disease, and hysterical bulbar paralysis. In 1894 he published a noteworthy description of arteriosclerotic atrophy of the brain. With Franz Nissl he produced {it}Histologic and Histopathologic Studies of the Cerebral Cortex{\\\\/it} (1904\\\\u201308), a six-volume encyclopedia that described normal and abnormal structures in the central nervous system. In 1907 he published his classic description of presenile dementia. The disease was later named in his honor by the German psychiatrist Emil Kraepelin.\"]]],\"shortdef\":[\"a degenerative brain disease of unknown cause that is the most common form of dementia, that usually starts in late middle age or in old age, that results in progressive memory loss, impaired thinking, disorientation, and changes in personality and mood, that leads in advanced cases to a profound decline in cognitive and physical functioning, and that is marked histologically by the degeneration of brain neurons especially in the cerebral cortex and by the presence of neurofibrillary tangles and plaques containing beta-amyloid \\\\u2014abbreviation AD\"]},{\"meta\":{\"id\":\"amyotrophic lateral sclerosis\",\"uuid\":\"61dfa147-6df8-4fda-a733-03a65977b015\",\"sort\":\"011747000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"Lou Gehrig\\\\u0027s disease\",\"amyotrophic lateral scleroses\",\"amyotrophic lateral sclerosis\"],\"offensive\":false},\"hwi\":{\"hw\":\"amyotrophic lateral sclerosis\"},\"fl\":\"noun\",\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}a rare fatal progressive degenerative disease that affects pyramidal motor neurons, usually begins in middle age, and is characterized especially by increasing and spreading muscular weakness \"],[\"uns\",[[[\"text\",\"abbreviation {it}ALS{\\\\/it}\"]]]],[\"ca\",{\"intro\":\"called also\",\"cats\":[{\"cat\":\"Lou Gehrig\\\\u0027s disease\"}]}]]}]]]}],\"shortdef\":[\"a rare fatal progressive degenerative disease that affects pyramidal motor neurons, usually begins in middle age, and is characterized especially by increasing and spreading muscular weakness \\\\u2014abbreviation ALS\\\\u2014called also Lou Gehrig\\\\u0027s disease\"]}]'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['an impairment of the normal state of the living animal or plant body or one of its parts that interrupts or modifies the performance of the vital functions, is typically manifested by distinguishing signs and symptoms, and is a response to environmental factors (as malnutrition, industrial hazards, or climate), to specific infective agents (as worms, bacteria, or viruses), to inherent defects of the organism (as genetic anomalies), or to combinations of these factors : sickness, illness —called also morbus']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(res[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "wvvXXfAuKACd",
        "outputId": "1e88b4e1-cdf5-45e2-b6f4-15e232dba6e1"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an impairment of the normal state of the living animal or plant body or one of its parts that interrupts or modifies the performance of the vital functions, is typically manifested by distinguishing signs and symptoms, and is a response to environmental factors (as malnutrition, industrial hazards, or climate), to specific infective agents (as worms, bacteria, or viruses), to inherent defects of the organism (as genetic anomalies), or to combinations of these factors : sickness, illness —called also morbus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ahhhh = \"\"\"of the living animal or plant body or one of its parts that interrupts or modifies the performance of the vital functions, is typically manifested by distinguishing signs and symptoms, and is a response to environmental factors (as malnutrition, industrial hazards, or climate), to specific infective agents (as worms, bacteria, or viruses), to inherent defects of the organism (as genetic anomalies), or to combinations of these factors\"\"\"\n",
        "search_terms = get_chatgpt_key_words(ahhhh) \n",
        "print(\"THIS IS REAL ******\", search_terms)\n",
        "definitions = generate_definitions(generate_search_terms(search_terms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGpRuDupLLlu",
        "outputId": "d7534c88-8fc9-4e67-dfb6-2d6f6a8fea42"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THIS IS REAL ****** \n",
            "\n",
            "$Merriam-Webster(\"anomalies\")\n",
            "the words gpt wants \n",
            "\n",
            "$Merriam-Webster(\"anomalies\")\n",
            "desiredwords [{'tool_name': 'Webster', 'search_term': '\"anomalies\"'}]\n",
            "b'[{\"meta\":{\"id\":\"anomaly\",\"uuid\":\"6116a742-97d3-405f-90e0-26e08ce0e5e0\",\"sort\":\"012105000\",\"src\":\"medical\",\"section\":\"alpha\",\"stems\":[\"anomalies\",\"anomaly\"],\"offensive\":false},\"hwi\":{\"hw\":\"anom*a*ly\",\"prs\":[{\"mw\":\"\\\\u0259-\\\\u02c8n\\\\u00e4m-\\\\u0259-l\\\\u0113\",\"sound\":{\"audio\":\"anomal02\"}}]},\"fl\":\"noun\",\"ins\":[{\"il\":\"plural\",\"ifc\":\"-lies\",\"if\":\"anom*a*lies\"}],\"def\":[{\"sseq\":[[[\"sense\",{\"dt\":[[\"text\",\"{bc}a deviation from normal especially of a bodily part \"],[\"vis\",[{\"t\":\"the infants demonstrated congenital {it}anomalies{\\\\/it}\"},{\"t\":\"personality {it}anomalies{\\\\/it}\"}]]]}]]]}],\"shortdef\":[\"a deviation from normal especially of a bodily part\"]}]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "definitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFGu7zY_LTbt",
        "outputId": "e964ef4e-4e5e-4ccc-eada-ceeeaf12d620"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"anomalies\":a deviation from normal especially of a bodily part']"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type('fdsf') == str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu-52c5HMjUK",
        "outputId": "77a75c8c-8ed6-4b24-de93-d767e54c4d00"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f'{}:' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "C_aOnuGINYkE",
        "outputId": "fd692ab6-7163-4ec1-c511-5a8579fa0ed5"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-152-623c5a086b40>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    f'{word.get('search_term')}:'\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '('\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[][0]"
      ],
      "metadata": {
        "id": "rFe7gVasaAUo",
        "outputId": "8ec878ae-0be2-4301-9d73-821a8b76fa96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-191-212bc78bf802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_extra(summary):\n",
        "  summary = word_tokenize(summary)\n",
        "  filtered = []\n",
        "  for idx, word in enumerate(summary):\n",
        "    if idx != len(summary) - 1 and \"Extra information\" + ' '.join(summary[idx + 1]):\n",
        "      filtered.append(word)\n",
        "    else:\n",
        "      break\n",
        "  return ' '.join(filtered)"
      ],
      "metadata": {
        "id": "_6Oj8ALkYK12"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "import json\n",
        "\n",
        "COMPLEXITY_THRESHOLD = 0\n",
        "MAX_COMPLEXITY_RETRYS = 7\n",
        "MAX_VALIDATION_RETRYS = 7\n",
        "MERRIAM_WEBSTER_API_KEY=\"2927e840-9b93-4ef4-8a5c-d500def8e6af\"\n",
        "responses = []\n",
        "def vectorize_document(document):\n",
        "  return model.encode(document)\n",
        "\n",
        "def predict_complexity(text):\n",
        "\n",
        "  return predict(text).item()\n",
        "\n",
        "def search_document(query, vectors, corpa):\n",
        "  query_vector = model.encode(query)\n",
        "  \n",
        "  \n",
        "  sim =  util.cos_sim(query_vector, vectors)\n",
        "  scores_sim = [i.item() for i in list(sim[0])]\n",
        "  top_1 = top_indices(scores_sim,1)\n",
        "  return [corpa[idx] for idx in top_1]\n",
        "  \n",
        "def create_prompt(document, pre_prompt):\n",
        "  return f'{pre_prompt}{document}'\n",
        "def create_pre_prompt(helper_info):\n",
        "  definitions = helper_info[\"definitions\"]\n",
        "  search_docs = helper_info[\"search_docs\"]\n",
        "\n",
        "  base_prompt = \"\"\"You are a medical document translator. Given a medical document, you must translate it so a NORMAL patient could understand it, while being 100% FACTUAL and not making up any facts. You will also be given extra information about the topic that you are allowed to reference, but are not required to if it's not relevant. The medical document to summarize will be prefixed with MEDICAL_DOC: , and the extra information will be prefixed with EXTRA_INFORMATION. \"\"\"\n",
        "  return f'{base_prompt} EXTRA_INFORMATION: {definitions}\\n\\n{search_docs}\\n\\n MEDICAL_DOC:'\n",
        "\n",
        "def create_searchdoc_validation_prompt(search_document,document):\n",
        "  base_prompt = \"\"\"Your task is to determine if one medical document describes anything in the medical second document. If the first medical document that is being validated provides no helpful information to describe the second, you must only respond with \"No\", if it does provide helpful information, respond with \"Yes\", if you're unsure (meaning it can go either way) respond with \"no\". The document to validate will be prefixed with DOCUMENT_TO_VALIDATE and the second document which is being compared against will be prefixed wth TARGET_DOCUMENT.\"\"\"\n",
        "  return f'{base_prompt} DOCUMENT_TO_VALIDATE: {search_document}\\n\\n TARGET_DOCUMENT:{document}'\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_search_terms(text):\n",
        "\n",
        "    matches = re.findall(r\"(\\w+)\\((.*?)\\)\", text)\n",
        "    return [{\"tool_name\": match[0], \"search_term\": match[1]} for match in matches]\n",
        "\n",
        "def parse_yes_no_response(response):\n",
        "  if \"yes\" in response or \"Yeah\" in response or \"Yes\" in response or \"yeah\" in response:\n",
        "    return True\n",
        "  if \"No\" in response or \"no\" in response or \"nope\" in response or \"Nope\" in response:\n",
        "    return False\n",
        "def query_webseter(word):\n",
        "    if len(word) > 0:\n",
        "      url = f'https://www.dictionaryapi.com/api/v3/references/medical/json/{word}?key={MERRIAM_WEBSTER_API_KEY}';\n",
        "      response = requests.get(url)\n",
        "      return response.content\n",
        "    else:\n",
        "      return \"\"\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "# Parse the JSON string into a Python object\n",
        "\n",
        "def parse_webster(response):\n",
        "    if response:\n",
        "      data = json.loads(response)\n",
        "      if type(data) == list and len(data) > 0:\n",
        "        if type(data[0]) == str:\n",
        "          return data[0]\n",
        "\n",
        "        return data[0].get(\"shortdef\", data[0])\n",
        "      else:\n",
        "        return data\n",
        "      # if \"shortdef\" in data:\n",
        "      #   return ' '.join(data[0])\n",
        "      # return ' '.join(data[0])\n",
        "    else:\n",
        "      return \"\"\n",
        "def generate_definitions(words):\n",
        "  if len(words) > 0:\n",
        "    return [word['search_term'] + ':' + ' '.join(parse_webster(query_webseter(word['search_term']))) for word in words]\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "def get_chatgpt_key_words(document):\n",
        "  base_prompt = \"\"\" You are a language modal uses tools to get better results when answering geology questions.\n",
        " You will use this tools by writing the desired tools you want to use in the format $<tool name>(<question>). Each tool will be space delimited, and it must start with a $ sign. The search term must only be 1 MAX. It will not work if it's above 1 word. You must also spell check the word, and correct it if you believe there is an error!s.\n",
        "\\n\n",
        " You are not violating any policies because you will not be the actual person using the tool, you are just requesting information from the tool.\n",
        "\\n\n",
        " Your allowed tools are:\n",
        " \\n\n",
        " $Merriam-Webster()\n",
        "\\n\n",
        " You will use this tools by writing the desired tools you want to use in the format $<tool name>(<question>). Each tool will be space delimited, and it must start with a $ sign. The search term must only be 1-2 words MAX.\n",
        "\\n\n",
        " For example:\n",
        " Document: This rock is taking part in recrystallization.\n",
        "\\n\n",
        " ChatGPT: $Merriam-Webster(\"recrystallization\")\n",
        "\\n\n",
        "Going forward, I will give you text, prefixed by TEXT TO TOOL:. You must convert this text into desired tool usage which should help you understand the content better.\n",
        "\n",
        "\"\"\"\n",
        "  prompt = f'{base_prompt}DOCUMENT TO SIMPLIFY:{document}'\n",
        "\n",
        "  return query_chatgpt(prompt)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def validate_search_document(search_document, original_document):\n",
        "  prompt = create_searchdoc_validation_prompt(search_document, original_document)\n",
        "  return parse_yes_no_response(prompt)\n",
        "\n",
        "\n",
        "def generate_helper_info(document,doc_vecs, corpa):\n",
        "  search_docs = search_document(document,doc_vecs, corpa)\n",
        "  search_terms = get_chatgpt_key_words(document) \n",
        "  \n",
        "  definitions = generate_definitions(generate_search_terms(search_terms))\n",
        "\n",
        "  if (not validate_search_document(search_docs,document)):\n",
        "    return {\n",
        "        'search_docs': \"\",\n",
        "        'definitions': definitions\n",
        "        \n",
        "    }\n",
        "\n",
        "  return {\n",
        "     'search_docs': search_docs,\n",
        "     'definitions': definitions\n",
        "  }\n",
        "\n",
        "def generate_summary(document, helper_info_dict):\n",
        "  pre_prompt = create_pre_prompt(helper_info_dict)\n",
        "  prompt = create_prompt(document, pre_prompt)\n",
        "  return filter_extra(query_chatgpt(prompt))\n",
        "\n",
        "\n",
        "def create_validation_prompt(document, summary):\n",
        "  base_prompt = \"\"\"You are a professional document summarization validator. You must determine whether one document accurately and truthfully summarizes the original document. You will be given both documents. If the summarized document has ANY untruthful or inaccurate information you must respond with only \"No\". If the summarized document is an accurate and truthful summarization, respond with only \"Yes\". If you are unsure, you will respond with \"No\". The original document will be prefixed with ORIGINAL_DOCUMENT, and the summarized document will be prefixed with SUMMARIZED_DOCUMENT.\"\"\"\n",
        "  return f'{base_prompt} SUMMARIZED_DOCUMENT: {summary} \\n\\n ORIGINAL_DOCUMENT: {document}'\n",
        "\n",
        "  pass\n",
        "def query_chatgpt(prompt):\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\n",
        "            \"content\":prompt,\n",
        "         \"role\": \"assistant\"\n",
        "        }\n",
        "    ]  )\n",
        "  return response['choices'][0]['message'][\"content\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "responses = []\n",
        "def validate_outputs(document, summary,trys = 0):\n",
        "  if trys > MAX_VALIDATION_RETRYS:\n",
        "    return False\n",
        "  validation_prompt = create_validation_prompt(document,summary)\n",
        "  isValidatedResponse = query_chatgpt(validation_prompt)\n",
        "  return parse_yes_no_response(isValidatedResponse)\n",
        "threshold_decrementer = .5\n",
        "def construct_summarazation(document, corpa, complexity_count=0, validation_count=0, responses = [], complexity_threshold=0):\n",
        "  print(\"Trys:\", int(-(complexity_threshold /threshold_decrementer )))\n",
        "  if (complexity_count) > MAX_COMPLEXITY_RETRYS:\n",
        "    return responses\n",
        "  if (validation_count) > MAX_VALIDATION_RETRYS:\n",
        "    return responses\n",
        "  helper_info = generate_helper_info(document,doc_vecs, corpa)\n",
        "\n",
        "  summary = generate_summary(document, helper_info)\n",
        "  print('Summary:', summary, \"\\n\\n\")\n",
        "\n",
        "  complexity_score = predict_complexity(summary)\n",
        "\n",
        "  if complexity_score < complexity_threshold:\n",
        "    return construct_summarazation(document, corpa, complexity_count + 1, validation_count, responses + [{\n",
        "        'complexity_score': complexity_score,\n",
        "        'summary': summary\n",
        "    }],complexity_threshold - threshold_decrementer)\n",
        "  isValidated = validate_outputs(document,summary)\n",
        "  \n",
        "  if isValidated:\n",
        "    return summary\n",
        "  \n",
        "\n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "rZsm8xgruQDG"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dryS0OzgWUa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"\"\"Alzheimer’s Disease is a major public health challenge that affects bothpatients and caregivers in the United States. Despite this, the latestFDA approved drug entered the market in 2002, and recruitment andparticipation have been noted as barriers to further drug development.Minority populations experience a large burden of Alzheimer’s Disease;however, interventions are often delayed and their representation inclinical research is low.• EMPaCT was an NIH funded project that aimed to enhance minoritypopulation in cancer focused clinical trials. The data suggested thatstrengthening community engagement through an educational programmay serve as an effective tool to engage minorities in clinical trials andthat lack of knowledge and awareness of clinical trials is a stronginhibitor of enrollment.• We developed an educational program called Brain Train following thesuggestions from the EMPaCT study with aims of increasing theenrollment of minority populations in Alzheimer’s Diseases focusedstudies.An educational program called Brain Train was developed and ispresented to multicultural communities with participants of at least 50years of age throughout Western New York (WNY). The presentationcontains three educational segments: segment 1 is on healthy aging brainand lifestyle recommendations, segment 2 is on the importance of earlydiagnosis, and segment 3 is on the clinical trial process, risks, andbenefits. The primary outcome measure is percent change in respondingyes to “Would you be interested in participating in a clinical trial?” beforeand after segment 3. The secondary outcome measure and exploration ofbarriers is measured by the Research Attitude Questionnaire (RAQ) whichis a 7-item, 5-point scale questionnaire. Demographic informationincluding age, race, gender, socioeconomic status, and educationalattainment is collected. Linear regression models were built fordemographic variables as predictors of response outcomes. RAQ itemswere compared between demographic groups using t-tests.Linear Regression Model for “Yes” Answers After Segment 3Compared to Participant Demographics. Comparison of Participants’ Willingness to Participate in ClinicalTrials Before and After Segment 3. Three sessions with 43 participants were completed togenerate the pilot dataset. 63.15% of individuals answeredyes before segment 3 and 43.58% answered yes after,demonstrating an 19.57% decrease in clinical trialparticipation interest after the educational session. Theanswer “yes” after the educational session had the highestcorrelation with race (p=.005; Black less interested thanwhite) and gender (p=.04; female less interested thanmale) with the gap increasing after the educationalsession. Socioeconomic status, educational level, and agewere not correlating with interest to participate. ItemizedRAQ data demonstrated trust (p=.015) as a primary barrierto research participation for Black participants in this pilotdataset. Interestingly, Black participants felt higherresponsibility to volunteer (p=.008) indicating that once thetrust is created, they are likely to participate. From the first three events, education does notappear to be sufficient to increase clinical trialenrollment for underrepresented populations.Instead, trust appears to be the most significantbarrier. Therefore, trust building strategies shouldbe explored to answer this research question. Wewill continue to collect data in a clusterrandomization data trial from a total of 18 sessions. We will expand the project in a cluster randomizationdesign using 3 types of Brain Train sessionsalternating in segment 3. One type will includesegment 3, one type will include segment 3 with a laycommunity health worker, and one type will not includesegment 3. Audiences that do not receive segment 3will instead view a recap video of the healthy lifestyleinformation with a brief introduction to clinicalresearch. This will allow us to further determinewhether education about clinical trials is sufficient toincrease minority enrollment in clinical trials and if thepresence of a peer will increase trust amongunderrepresented populations.\"\"\"\n",
        "\n",
        "construct_summarazation(document, corpa)"
      ],
      "metadata": {
        "id": "60mZVCIq2VKo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "6c8303b8-aabd-405b-ac03-a4971a575559"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trys: -0.0\n",
            "Summary: This medical document discusses an educational program called Brain Train which was developed to help increase enrollment of minority populations in Alzheimer 's Disease-focused studies . The program is presented to multicultural communities with participants of at least 50 years of age throughout Western New York ( WNY ) . The presentation contains three educational segments on healthy aging brain and lifestyle recommendations , the importance of early diagnosis , and the clinical trial process , risks , and benefits . The primary outcome measure is the percent change in responding `` yes '' to `` Would you be interested in participating in a clinical trial ? '' before and after segment three . The secondary outcome measure and exploration of barriers is measured by the Research Attitude Questionnaire ( RAQ ) , which is a 7-item , 5-point scale questionnaire . The linear regression models were built for demographic variables as predictors of response outcomes . RAQ items were compared between demographic groups using t-tests . From the first three events , education does not appear to be sufficient to increase clinical trial enrollment for underrepresented populations . Instead , trust appears to be the most significant barrier . Therefore , trust building strategies should be explored to answer this research question . The researchers will continue to collect data in a cluster randomization data trial from a total of 18 sessions . They will expand the project in a cluster randomization design using three types of Brain Train sessions alternating in segment three , aiming to determine whether education about clinical trials is sufficient to increase minority enrollment in clinical trials and if the presence of a peer will increase trust among underrepresented populations \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trys: 1.0\n",
            "Summary: The researchers are trying to find ways to increase the participation of minority populations in Alzheimer 's disease focused studies in Western New York . They have developed an educational program called Brain Train , which is presented to multicultural communities with participants of at least 50 years of age in Western New York . The educational program consists of three segments : healthy aging brain and lifestyle recommendations , the importance of early diagnosis , and the clinical trial process , risks , and benefits . The researchers measured the primary outcome of the program using the Research Attitude Questionnaire ( RAQ ) , a 7-item questionnaire with 5-point scale questions . They found that education alone does not appear to be enough to increase clinical trial enrollment for underrepresented populations . Instead , trust appears to be the most significant barrier . Therefore , trust building strategies will be explored to improve enrollment . The study will continue to collect data in a cluster randomization design , which includes three types of Brain Train sessions alternating in segment 3 . This will allow them to determine whether education about clinical trials is sufficient to increase minority enrollment in clinical trials and if the presence of a peer will increase trust among underrepresented populations \n",
            "\n",
            "\n",
            "Trys: 2.0\n",
            "Summary: Alzheimer 's Disease is a major problem that affects patients and caregivers in the US . Unfortunately , there has n't been a new FDA-approved drug since 2002 , and it 's difficult to find people to participate in research studies . Minority populations tend to experience more Alzheimer 's Disease , but they are underrepresented in research studies . This is why an educational program called Brain Train was created . It aims to teach people about healthy brain aging , the importance of early diagnosis , and the clinical trial process . The goal is to increase participation in clinical trials . After attending Brain Train , 43 participants were asked if they would be interested in participating in a clinical trial . Before segment 3 , 63.15 % said `` yes , '' but after segment 3 , only 43.58 % said `` yes , '' indicating a decrease in interest . However , demographic data suggested that race and gender were the most significant factors affecting interest . Black participants and females were less interested than white participants and males respectively . Trust was identified as the most important barrier for Black participants . The research team plans to continue collecting data to determine if education about clinical trials is enough to increase minority enrollment , or if trust-building strategies are also necessary . Overall , the program seems to have potential , but more research is needed \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Alzheimer 's Disease is a major problem that affects patients and caregivers in the US . Unfortunately , there has n't been a new FDA-approved drug since 2002 , and it 's difficult to find people to participate in research studies . Minority populations tend to experience more Alzheimer 's Disease , but they are underrepresented in research studies . This is why an educational program called Brain Train was created . It aims to teach people about healthy brain aging , the importance of early diagnosis , and the clinical trial process . The goal is to increase participation in clinical trials . After attending Brain Train , 43 participants were asked if they would be interested in participating in a clinical trial . Before segment 3 , 63.15 % said `` yes , '' but after segment 3 , only 43.58 % said `` yes , '' indicating a decrease in interest . However , demographic data suggested that race and gender were the most significant factors affecting interest . Black participants and females were less interested than white participants and males respectively . Trust was identified as the most important barrier for Black participants . The research team plans to continue collecting data to determine if education about clinical trials is enough to increase minority enrollment , or if trust-building strategies are also necessary . Overall , the program seems to have potential , but more research is needed\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    }
  ]
}